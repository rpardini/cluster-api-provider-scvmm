Bugs:
v Apparently, the scvmmmachine controller needs to set the ProviderID on the node
  (The kubeadm provider doesn't seem to be doing that)
  . Add a runcmd at the end?  Not sure that works with all images (especially Talos)
  . Just stick it in the kubeadm templates somehow?  (Doesn't work well with other providers)
  v Run it remotely via the ControlPlaneEndpoint, assuming the nodename will be the hostname?
  * It might be that this just caused one of the controlplanes to half-degrade to a workernode
- The machinecontroller needs to watch something else for changes (machine, cluster or scvmmcluster)
  Because now, it sometimes doesn't go on reconciling when the owner data is ready

Todo:
- What should the cluster reconciler do?  Maybe generate a kAPI vip or something?
  . Which responsibilities is the cluster controller supposed to have?
  . Looks like at least setting the ControlPlaneEndpoint correctly
  . Isn't there a chicken-egg issue where the endpoint needs to be known before the first
    control plane has been initialized?
  . Easiest is probably defining it in the spec, and then using that to setup the LB
    But does the kubeadm init need the endpoint?  The kubeadm join certainly does.
- Does the cluster reconciler also have to apply a CNI networker?
  (Maybe.  There seems to be a 'cni' label on the cluster)

- Doing kubernetes-api loadbalancing
  . MetalLB?
  . Keepalived?
  . Choice?

v Add the possibility for adding more than one disk to the VM

- The (reference) docker infra-provider also seems to have a watch on other resources to
  trigger reconciliation.  Look into that and do that also

- Some kind of domain join action?  Or should that be done with user-supplied user-data?

- Make GenerateVMName atomic (probably works OK now because the controller is single threaded)
  . Needs some way to set and get values from the VMMServer somewhere
  . Alternatively, handle name clashes (currently it would create two VMs with the same name)
  . Do we need to store the unique ID of the VM in the spec?  There's the ProviderID, maybe
    use that to query the VM status instead of the name.  But that's currently BiosGUID, should
    that be the VM unique ID ?

- Regularly check the status of the VMs
  . What to do when somebody turns off the VM externally?
    Currently it will probably recreate the cloud-init and then boot it up again,
    that would surprise some sysadmins
  . Think about error scenarios

- Keep the WinRM powershell running (stop it after a number of seconds of inactivity)
   (Powershell startup and module loading takes a few seconds each time)
   . Probably use a channel to send the commands and get back the results?
   . Needs decent error handling for reconnection and stuff

- Better handling of external errors

- Maybe look into setting networking via hyper-v integration instead of cloud-init networkconfig ??

